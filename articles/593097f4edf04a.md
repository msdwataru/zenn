---
title: "ChatGPT にドメイン知識を与える 4 つの方法"
emoji: "🦙"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["llamaindex", "gpt4", "gpt3", "chatgpt", "autogpt"]
published: false
publication_name: "geniee"

---

## はじめに

ChatGPT や LLM を組み込んだサービスをより幅広いユースケースで活用していくためには、社内のドキュメントやチャット履歴、自社サービスの保持するデータといった、**ドメイン知識に基づいた回答をしてくれる**といったことが求められてきます。
この記事では、そのようなドメイン知識を事前知識として GPT に与えてその情報に基づいた回答を行えるようにするための方法4つを紹介したいと思います。

## プロンプトエンジニアリング

### プロンプトエンジニアリングとは

プロンプトエンジニアリングとは、**ユーザーが言語モデルから期待する回答を得られるように、プロンプト（入力文）の設計を工夫する手法**のことです。これは、言語モデルの回答精度を向上させる主要な手段の一つとなります。プロンプトエンジニアリングの具体的な手法についてはすでに多くの手法が確立されており、それらがまとまった Prompt Engineering Guide というものも公開されています。
https://www.promptingguide.ai/jp/introduction/basics

### プロンプトエンジニアリングを利用したドメイン知識の獲得方法

その中でドメイン知識を与える方法として最も近いのが知識生成（Generate Knowledge） プロンプティングです。これは事前に**ドメイン知識を含むプロンプトを設定する**ことで、モデルの回答精度を向上させることが可能となります。
以下に GENIEE SFA/CRM のヘルプページに関するドメイン知識を与えたうえで関連する URL を回答する例を示します。

```
hoge
```

### メリデメ

プロンプトエンジニアリングによってドメイン知識を元にした回答をさせる方法は最もシンプルでコストもプロンプトが多くなければそこまでかかりません。しかし、入力可能な最大トークン数以上の事前知識を与えることができないといった制約があります。GPT-3.5 では 4k, GPT-4 では 8k か 32k までの上限があります。

## Fine-tuning

### Fine-tuning とは

Fine-tuning とはすでに学習済みのモデルに対して、追加の学習データを用いた追加学習を行うことでそのデータに最適化されたモデルを再構築する手法です。LLM についても Fine-tuning の手法をもちいることで、追加データに特化した回答を期待することができます。

### Fine-tuning の利用方法

OpenAI の提供する言語モデルを Fine-tuning する方法は公式ページで説明がされており、OpenAI の提供する CLI から利用することが可能です。
https://platform.openai.com/docs/guides/fine-tuning
追加学習のための学習データは以下のような入力（prompt）と出力（completion）のペアの JSONL 形式となっています。学習後のモデルの呼び出しも CLI や python の openai ライブラリなどから可能となっています。

```
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
...
```

### メリデメ

メリットとしては、プロンプトエンジニアリングのように与える事前知識の量に制限がない点が挙げられます。
デメリットとしては、APIを利用する場合、追加学習とそのモデルを利用する際のコストがかなり高いこと（Davinci でのトレーニングは 1K トークンあたり$0.0300、使用は 1K トークンあたり$0.1200）があります。また、記事執筆時点で Fine-tuning をサポートしているのは GPT-3 までという制限もあります。そのため、Fine-tuningを行うのであればオープンソースのLLMに対して行うのが良さそうに思います。
実際の精度については、コスト対効果を考慮してまだ試していないため、どの程度追加データに適応できるのかは未知数です。

## Embedding

### Embedding とは

言語処理や機械学習分野における Embedding とは、言葉や項目、カテゴリなどを低次元の実数ベクトルに変換する技術のことを指します。特に自然言語処理の分野においては単語や文章をベクトル表現に変換することを指し、それらのベクトル表現を利用することで単語や文章の意味的な類似性などを計算することが可能になります。

### Embedding を用いたドメイン知識の獲得方法
Embeddingの手法をベースにしてドメイン知識をLLMモデルに獲得させるためのツールとして、LlamaIndexに代表されるようなIndex化のライブラリが存在しています。
これらのツールでは、まず**Webページやcsvなどの情報をEmbeddingによりベクトル化したものをそれぞれIndexとして保存しておきます**。そして**ユーザー入力のベクトル表現とそれぞれのIndexとの距離を計算した上で関連するIndexを事前知識としてプロンプトに与え**、回答を行なっています。
以下に GENIEE SFA/CRM のヘルプページに関するドメイン知識を与えたうえで問い合わせに回答する例を示します。

```
hoge
```


LlamaIndexのライブラリを利用すればさまざまなデータソースからIndex化するところや最終的な予測までを行なってくれますが、EmbeddingをOpenAIのEmbeddingのAPIを利用するためそこで料金がかかってきます。

### メリデメ
Llama Hubにてcsvデータ等のローカルデータ以外にも、ConfluenceやGoogle Drive等からIndexを作成できるため、**社内データなどの独自データを活用できる幅がかなり広がります**。データ量についてもそれぞれのIndexでのトークン上限はあるものの、Indexの数自体には制限はないためかなり多くの知識を与えられます。
デメリットというか難しいポイントとしては、Index化の粒度やデータの質に回答が依存するため、そこのノウハウやデータクレンジングが一定必要になる点や、数十MBを超えるような大きなデータではコストやEmbeddingするのに時間がかかったりします。また、ライブラリの更新頻度が非常に多く、バージョンによって使い方がかなり変わるため、そこを確認しながら利用する必要があります。
## Grounding, ReAct
※個人的に最も活用幅が広く、回答の精度も出せる汎用的な方法だと思っています
### Grounding, ReActとは
AutoGPTやChatGPT Plusで提供されるブラウジング機能、その他のプラグインのように、LLMモデルが外部データにアクセスしてそれをコンテキストとしてやりとりを行わせるような考え方をGroundingと呼びます。これは**LLMの出力をプロンプトエンジニアリングによって外部データやAPIアクセスのためのコマンドやクエリを出力させ**、その結果をプログラムが実行し、さらにその結果を用いてLLMが最終的な出力を生成するといった方法になっています。
さらにその**Grounding自体をLLMに出力させて複雑なタスクに対して段階的に実行計画を立てて実行させる**ような考え方をReAct (Reasoning and Acting) と呼びます。AutoGPTやChatGPT Plusのプラグインでは、一回だけのブラウジングやAPI実行だけでなく、プロンプトに応じて柔軟に実行コマンドや回数を変えていることからReActの考え方が実装されています。AutoGPTの実装については下記の記事が3つに分けて説明をしており、特にその2では具体的なGroundingやReActの実現のためのプロンプトが解説されています。
https://zenn.dev/asopitech/articles/20230415-221612_1

### Groundingを用いたドメイン知識の活用例
今回は簡単な例としてGoogle検索APIを実行するためのキーワード抽出をするようなプロンプトを考えます。キーワードの抽出を行うことができれば、あとは後段のプログラムによって検索をかけ、結果をクローリングやスクレイピングし、それをドメイン知識としてプロンプトに与え、最終的な結果をLLMに出力させることができます。
API実行のための情報を再現性高く抽出するためには**出力フォーマットを指定する**ことが重要となります。キーワード抽出のためのプロンプト例を以下に示します。

```python
prompt = f"""
次の質問に対してgoogle検索を行うためのキーワードを以下の形式で抽出してください。
キーワードが複数ある場合は複数を半角スペース区切りで出力してください。

FORMAT:
{{
    "keyword": "<keyword>"
}}

QUESTION:
{question}
"""
```

このようなプロンプトを用意した上で、「大谷翔平の2023年の成績は？」というquestionをした場合、結果の出力は以下のようになります

```json
{
    "keyword": "大谷翔平 2023 成績"
}
```

あとはこの結果をパースして検索APIを実行することで、外部APIを利用したLLMの活用が可能となります。この例では情報を取得するAPIを利用しましたが、作成や編集等のAPI等も同様の方法で実行が可能なため、実質**自然言語を用いてCRUD操作全てを実現することができます**。
さらにプロンプトを工夫すれば、実行可能なAPI情報を複数にしてユーザー入力に対して適切なAPIの実行情報を出力させたり、ReActのようにそれらを組み合わせた複雑な処理も行うことができます。


### メリデメ
APIの実行情報を出力するだけで外部データの参照が可能なため、この方法の利用可能範囲は広大です。さらに、取得したデータをLLMで要約したり、ベクトル化して近傍計算により利用可能にする等の工夫を施すことで、トークン数の上限問題も回避できます。
ただし、一度の実行で事前のプロンプトを含む複数回のLLM生成を行う場合があるため、トークンの利用量には注意が必要です。また、GPT3.5とGPT4では、APIの実行情報の出力精度に大きな差があります。そのため、3.5を利用してのコスト削減も精度とのトレードオフになるかと思います。

## まとめ

今回はLLMモデルで社内文書や外部データなどのドメイン知識を利用するための方法を4つ紹介しました。それぞれで、与えられる知識量、精度、コスト、実装難易度などの観点でメリデメがあるかと思うので、実現したいユースケースや機能に応じて使い分けをするための参考になれば幸いです。


## 参考資料

- https://www.promptingguide.ai/jp/introduction/basics
- https://platform.openai.com/docs/guides/fine-tuning
- https://zenn.dev/asopitech/articles/20230415-221612_1

