---
title: "ChatGPTにドメイン知識を与える4つの方法"
emoji: "🦙"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["llamaindex", "gpt4", "gpt3", "chatgpt", "autogpt"]
published: false
publication_name: "geniee"
---
## はじめに
ChatGPTやLLMを組み込んだサービスをより幅広いユースケースで活用していくためには、社内のドキュメントやチャット履歴、自社サービスの保持するデータといった、ドメイン知識に基づいた回答をしてくれるといったことが重要になってきます。
この記事では、そのようなドメイン知識を事前知識としてGPTに与えてその情報に基づいた回答を行えるようにするための方法を4つ紹介したいと思います。


## プロンプトエンジニアリング
### プロンプトエンジニアリングとは
プロンプトエンジニアリングとは、ユーザーが言語モデルから期待する回答を得られるように、プロンプト（入力文）の設計を工夫する手法のことです。これは、言語モデルの回答精度を向上させる主要な手段の一つとなります。プロンプトエンジニアリングの具体的な手法についてはすでに多くの手法が確立されており、それらがまとまったPrompt Engineering Guideというものも公開されています。
https://www.promptingguide.ai/jp/introduction/basics



### プロンプトエンジニアリングを利用したドメイン知識の獲得方法
その中でドメイン知識を与える方法として最も近いのが知識生成（Generate Knowledge） プロンプティングです。これは事前にドメイン知識を含むプロンプトを設定することで、モデルの回答精度を向上させることが可能となります。
以下にGENIEE SFA/CRMのヘルプページに関するドメイン知識を与えたうえで関連するURLを回答する例を示します。

```
hoge
```


### メリデメ
プロンプトエンジニアリングによってドメイン知識を元にした回答をさせる方法は最もシンプルでコストもプロンプトが多くなければそこまでかかりません。しかし、入力可能な最大トークン数以上の事前知識を与えることができないといった制約があります。GPT-3.5では4k, GPT-4では8kか32kまでの上限があります。

## Fine-tuning
### Fine-tuningとは
Fine-tuningとはすでに学習済みのモデルに対して、追加の学習データを用いた追加学習を行うことでそのデータに最適化されたモデルを再構築する手法です。LLMについてもFine-tuningの手法をもちいることで、追加データに特化した回答を期待することができます。

### Fine-tuningの利用方法
  OpenAIの提供する言語モデルをFine-tuningする方法は公式ページで説明がされており、OpenAIの提供するCLIから利用することが可能です。
  https://platform.openai.com/docs/guides/fine-tuning
  追加学習のための学習データは以下のような入力（prompt）と出力（completion）のペアのJSONL形式となっています。学習後のモデルの呼び出しもCLIやpythonのopenaiライブラリなどから可能となっています。
```
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
...
```


### メリデメ
メリットとしては、プロンプトエンジニアリングのように与える事前知識の量に制限がない点が挙げられます。デメリットとしては、追加学習とそのモデルを利用する際のコストがかなり高いこと（Davinciでのトレーニングは1Kトークンあたり$0.0300、使用は1Kトークンあたり$0.1200）があります。また、記事執筆時点でFine-tuningをサポートしているのはGPT-3までという制限もあります。実際の精度については、コスト対効果を考慮してまだ試していないため、どの程度追加データに適応できるのかは未知数です。


## Embedding
### Embeddingとは
言語処理や機械学習分野におけるEmbeddingとは、言葉や項目、カテゴリなどを低次元の実数ベクトルに変換する技術のことを指します。特に自然言語処理の分野においては単語や文章をベクトル表現に変換することを指し、それらのベクトル表現を利用することで単語や文章の意味的な類似性などを計算することが可能になります。
### Embeddingを用いたドメイン知識の獲得方法


## コマンドを覚えさせる
  - コマンドを使ってChatGPTに特定の行動や知識を覚えさせる方法について解説します。
  - コマンド設定の効果的な戦略や考慮すべき点について詳しく説明します。

## まとめ
  - 各方法の長所と短所、それぞれが適する状況についてまとめます。
  - ChatGPTにドメイン知識を与える全体的な戦略やフレームワークについて説明します。

## 参考資料
- https://www.promptingguide.ai/jp/introduction/basics
- https://platform.openai.com/docs/guides/fine-tuning
